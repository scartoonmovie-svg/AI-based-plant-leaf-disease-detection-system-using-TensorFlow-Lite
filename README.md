# ğŸŒ¾ AgriGuard v1 - Smart Agriculture Assistant

**Production-Grade AI System for Food Safety & Plant Health Detection**

AgriGuard v1 is an offline, Raspberry Pi-based AI system that helps farmers and home users detect:
- **Kitchen Mode**: Whether vegetables (tomato, potato, onion) are fresh or spoiled
- **Farm Mode**: Whether plant leaves (tomato, potato) are healthy or diseased

---

## ğŸš€ Key Features

### Core Capabilities
- âœ… **Offline Operation** - Works without internet connection
- âœ… **Real-time Detection** - Instant results from camera capture
- âœ… **Voice Feedback** - Spoken results in multiple languages
- âœ… **Web Interface** - Modern, responsive web UI
- âœ… **CLI Interface** - Simple command-line interface
- âœ… **Scan History** - Database of all scans with timestamps
- âœ… **Multi-Crop Support** - Tomato, Potato, Onion
- âœ… **Production Ready** - Error handling, logging, health checks

### Advanced Features
- ğŸ¯ **High Accuracy** - Transfer learning with MobileNetV2/EfficientNet
- ğŸ“Š **Statistics Dashboard** - View scan history and trends
- ğŸ”„ **Model Versioning** - Easy model updates
- ğŸŒ **Multi-language TTS** - English, Hindi, and more
- ğŸ“¸ **Image Storage** - All scanned images saved for review
- âš¡ **Fast Inference** - Optimized TFLite models for Raspberry Pi

---

## ğŸ“‹ Requirements

### Hardware
- **Raspberry Pi 4** (recommended) or **Pi Zero 2W** (fully supported with optimizations)
- **Raspberry Pi Camera Module** or USB webcam
- **Speaker** (wired or Bluetooth) for audio feedback
- **MicroSD Card** (32GB+ recommended, 64GB perfect)

### Software
- **Raspberry Pi OS** (Bullseye or later)
- **Python 3.8+**
- **Camera drivers** (libcamera for Pi Camera)

---

## ğŸ› ï¸ Installation

### On Raspberry Pi

1. **Clone or copy this repository to your Pi**

2. **Run setup script:**
   ```bash
   chmod +x setup_pi.sh
   ./setup_pi.sh
   ```

3. **Activate virtual environment:**
   ```bash
   source venv/bin/activate
   ```

4. **Train models on your laptop** (see Training section)

5. **Copy trained models to Pi:**
   ```bash
   # Copy .tflite files to models/fruit/ and models/leaves/
   ```

6. **Run AgriGuard:**
   ```bash
   # Web mode (recommended)
   python pi_app/main_pi.py --mode web
   
   # CLI mode
   python pi_app/main_pi.py --mode cli
   ```

7. **Access web interface:**
   - Open browser: `http://raspberry-pi-ip:5000`
   - Or on Pi: `http://localhost:5000`

### On Laptop (for Training)

1. **Run setup script:**
   ```bash
   chmod +x setup_laptop.sh
   ./setup_laptop.sh
   ```

2. **Activate virtual environment:**
   ```bash
   source venv/bin/activate
   ```

---

## ğŸ“ Training Models

### Data Preparation

Organize your training images in this structure:

```
data/raw/
â”œâ”€â”€ fruit/
â”‚   â”œâ”€â”€ tomato/
â”‚   â”‚   â”œâ”€â”€ fresh/
â”‚   â”‚   â””â”€â”€ spoiled/
â”‚   â”œâ”€â”€ potato/
â”‚   â”‚   â”œâ”€â”€ fresh/
â”‚   â”‚   â””â”€â”€ spoiled/
â”‚   â””â”€â”€ onion/
â”‚       â”œâ”€â”€ fresh/
â”‚       â””â”€â”€ spoiled/
â””â”€â”€ leaves/
    â”œâ”€â”€ tomato/
    â”‚   â”œâ”€â”€ healthy/
    â”‚   â””â”€â”€ diseased/
    â””â”€â”€ potato/
        â”œâ”€â”€ healthy/
        â””â”€â”€ diseased/
```

### Training Commands

```bash
# Train tomato fruit model
python training/train_unified.py --crop tomato --mode fruit --epochs 50

# Train potato fruit model
python training/train_unified.py --crop potato --mode fruit --epochs 50

# Train onion fruit model
python training/train_unified.py --crop onion --mode fruit --epochs 50

# Train tomato leaf model
python training/train_unified.py --crop tomato --mode leaf --epochs 50

# Train potato leaf model
python training/train_unified.py --crop potato --mode leaf --epochs 50
```

### Training Options

- `--base-model`: Choose `mobilenetv2` (faster) or `efficientnet` (more accurate)
- `--epochs`: Number of training epochs (default: 50)
- `--batch-size`: Batch size (default: 32)

### Model Output

Trained models are saved to:
- `models/{mode}/{crop_type}/{crop_type}_{mode}.tflite`
- `models/{mode}/{crop_type}/class_names.json`

Copy these files to your Raspberry Pi.

---

## ğŸ“– Usage

### Web Interface

1. Start web server:
   ```bash
   python pi_app/main_pi.py --mode web
   ```

2. Open browser and navigate to the Pi's IP address (port 5000)

3. Select crop type and scan mode

4. Click "Capture & Analyze"

5. View results and history

### CLI Interface

1. Start CLI:
   ```bash
   python pi_app/main_pi.py --mode cli
   ```

2. Follow on-screen menu prompts

3. Select crop type and mode

4. Results are displayed and spoken

---

## ğŸ—ï¸ Project Structure

```
AgriGuard/
â”œâ”€â”€ pi_app/              # Raspberry Pi application
â”‚   â”œâ”€â”€ main_pi.py      # Main entry point
â”‚   â”œâ”€â”€ web_app.py      # Flask web application
â”‚   â”œâ”€â”€ ui_cli.py        # CLI interface
â”‚   â”œâ”€â”€ camera_capture.py # Camera management
â”‚   â”œâ”€â”€ image_utils.py   # Image preprocessing
â”‚   â”œâ”€â”€ tflite_inference.py # Model inference
â”‚   â”œâ”€â”€ audio_utils.py   # Text-to-speech
â”‚   â”œâ”€â”€ database.py      # Scan history database
â”‚   â””â”€â”€ config.py        # Configuration
â”œâ”€â”€ training/            # Training scripts
â”‚   â”œâ”€â”€ train_unified.py # Unified training script
â”‚   â””â”€â”€ ...
â”œâ”€â”€ web/                 # Web interface
â”‚   â”œâ”€â”€ templates/      # HTML templates
â”‚   â””â”€â”€ static/         # CSS, JS, images
â”œâ”€â”€ data/               # Data directories
â”‚   â”œâ”€â”€ raw/           # Raw training images
â”‚   â”œâ”€â”€ processed/     # Processed data
â”‚   â”œâ”€â”€ captures/      # Captured images
â”‚   â””â”€â”€ scans.db       # SQLite database
â”œâ”€â”€ models/             # Trained models
â”‚   â”œâ”€â”€ fruit/         # Fruit models
â”‚   â””â”€â”€ leaves/        # Leaf models
â”œâ”€â”€ logs/              # Log files
â”œâ”€â”€ requirements.txt   # Python dependencies (laptop)
â”œâ”€â”€ requirements_pi.txt # Python dependencies (Pi)
â”œâ”€â”€ setup_pi.sh        # Pi setup script
â”œâ”€â”€ setup_laptop.sh    # Laptop setup script
â””â”€â”€ README.md          # This file
```

---

## ğŸ”§ Configuration

Edit `pi_app/config.py` to customize:

- Model paths
- Image size
- Confidence thresholds
- Camera settings
- Logging options

---

## ğŸ› Troubleshooting

### Pi Zero 2W Users

If you're using **Raspberry Pi Zero 2W**, see the detailed guide:
- **[Pi Zero 2W Optimization Guide](docs/PI_ZERO_2W_GUIDE.md)**

Key points:
- âœ… Fully supported with automatic optimizations
- âœ… Use MobileNetV2 models (not EfficientNet)
- âœ… CLI mode recommended for best performance
- âœ… 64GB SD card is perfect!

### Camera Issues

- **Camera not detected**: Check camera connection and drivers
- **Permission denied**: Add user to `video` group: `sudo usermod -a -G video $USER`
- **USB camera**: Update `CAMERA_INDEX` in `config.py`

### Model Issues

- **Model not found**: Ensure `.tflite` files are in `models/` directory
- **Low accuracy**: Retrain with more/better data
- **Slow inference**: Use MobileNetV2 instead of EfficientNet

### Audio Issues

- **No sound**: Check speaker connection and volume
- **TTS not working**: Install `espeak`: `sudo apt-get install espeak`

### Web Interface Issues

- **Can't access**: Check firewall and Pi's IP address
- **Port in use**: Change port: `--port 8080`

---

## ğŸ“Š Performance

### Model Sizes
- MobileNetV2: ~5-10 MB per model
- EfficientNet: ~15-25 MB per model

### Inference Speed (Raspberry Pi 4)
- MobileNetV2: ~50-100ms per image
- EfficientNet: ~150-300ms per image

### Accuracy
- Fruit detection: 85-95% (depends on data quality)
- Leaf detection: 80-90% (depends on data quality)

---

## ğŸ”® Future Enhancements

- [ ] Support for more crops (chili, brinjal, etc.)
- [ ] More disease types
- [ ] Mobile app companion
- [ ] Cloud sync (optional)
- [ ] Multi-language UI
- [ ] Batch processing mode
- [ ] Export reports (PDF)
- [ ] Integration with agricultural APIs

---

## ğŸ“ License

This project is open source. Feel free to use, modify, and distribute.

---

## ğŸ™ Acknowledgments

- **PlantVillage Dataset** - Reference for leaf disease data
- **TensorFlow Team** - ML framework
- **Raspberry Pi Foundation** - Hardware platform

---

## ğŸ“§ Support

For issues, questions, or contributions, please open an issue on the project repository.

---

**Made with â¤ï¸ for farmers and home users worldwide**
